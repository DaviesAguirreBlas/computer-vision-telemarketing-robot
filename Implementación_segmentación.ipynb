{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f1a84c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the model\n",
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH = 256\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "def get_model():\n",
    "\n",
    "    #Build the model\n",
    "    inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "    s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\n",
    "\n",
    "    #Contraction path\n",
    "    c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
    "    c1 = tf.keras.layers.Dropout(0.1)(c1)\n",
    "    c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "    p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "    c2 = tf.keras.layers.Dropout(0.1)(c2)\n",
    "    c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "    p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "    c3 = tf.keras.layers.Dropout(0.2)(c3)\n",
    "    c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "    p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "    c4 = tf.keras.layers.Dropout(0.2)(c4)\n",
    "    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "    p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
    "\n",
    "    c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "    c5 = tf.keras.layers.Dropout(0.3)(c5)\n",
    "    c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "\n",
    "    #Expansive path \n",
    "    u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = tf.keras.layers.concatenate([u6, c4])\n",
    "    c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "    c6 = tf.keras.layers.Dropout(0.2)(c6)\n",
    "    c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
    "\n",
    "    u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = tf.keras.layers.concatenate([u7, c3])\n",
    "    c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "    c7 = tf.keras.layers.Dropout(0.2)(c7)\n",
    "    c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
    "\n",
    "    u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = tf.keras.layers.concatenate([u8, c2])\n",
    "    c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "    c8 = tf.keras.layers.Dropout(0.1)(c8)\n",
    "    c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
    "\n",
    "    u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n",
    "    c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "    c9 = tf.keras.layers.Dropout(0.1)(c9)\n",
    "    c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "\n",
    "    outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bda34b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "model2= get_model()\n",
    "\n",
    "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "476fa8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"model_checpoints/checkpoint\"\n",
    "model2.load_weights(\"modelito_lazaro.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764e215d",
   "metadata": {},
   "source": [
    "## Código para Socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "353d362c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m client \u001b[38;5;241m=\u001b[39m socket\u001b[38;5;241m.\u001b[39msocket(socket\u001b[38;5;241m.\u001b[39mAF_INET, socket\u001b[38;5;241m.\u001b[39mSOCK_STREAM)\n\u001b[1;32m---> 11\u001b[0m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mADDR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend\u001b[39m(msg):\n",
      "\u001b[1;31mTimeoutError\u001b[0m: [WinError 10060] Se produjo un error durante el intento de conexión ya que la parte conectada no respondió adecuadamente tras un periodo de tiempo, o bien se produjo un error en la conexión establecida ya que el host conectado no ha podido responder",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import socket\n",
    "\n",
    "HEADER = 64\n",
    "PORT = 5055\n",
    "FORMAT = 'utf-8'\n",
    "DISCONNECT_MESSAGE = \"!DISCONNECT\"\n",
    "SERVER = \"10.101.57.67\"\n",
    "ADDR = (SERVER, PORT)\n",
    "\n",
    "client = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "client.connect(ADDR)\n",
    "\n",
    "def send(msg):\n",
    "    message = msg.encode(FORMAT)\n",
    "    msg_length = len(message)\n",
    "    send_length = str(msg_length).encode(FORMAT)\n",
    "    send_length += b' ' * (HEADER - len(send_length))\n",
    "    client.send(send_length)\n",
    "    client.send(message)\n",
    "    print(client.recv(2048).decode(FORMAT))\n",
    "\n",
    "    \n",
    "# send(\"Hello World!\")\n",
    "# input()\n",
    "# send(\"Hello Everyone!\")\n",
    "# input()\n",
    "# send(\"Hello Tim!\")\n",
    "\n",
    "# send(DISCONNECT_MESSAGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4076722",
   "metadata": {},
   "source": [
    "## Probando con Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e11790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#puntos para el centroide\n",
    "x_c = 0\n",
    "y_c = 0\n",
    "#color para el punto del centroide\n",
    "red = [0,0,255]\n",
    "\n",
    "# Establish capture\n",
    "cap = cv2.VideoCapture('VID_20220715_125458.mp4')\n",
    "while (cap.isOpened()):\n",
    "# Loop through each frame\n",
    "  # Read frame \n",
    "  ret, frame = cap.read()\n",
    "  img_1 = cv2.resize(frame, (256, 256))\n",
    "  original = img_1 # Para blending\n",
    "  #recurso para normalización\n",
    "  normalizedImg = np.zeros((256, 256))\n",
    "  #normalizamos la imagen\n",
    "  img= cv2.normalize(img_1,  normalizedImg, 0, 255, cv2.NORM_MINMAX)\n",
    "  #convertimos a array\n",
    "  imagen_lista = tf.keras.preprocessing.image.array_to_img(img)\n",
    "  #expandimos dimensiones para que pueda ser digerida por \"Input\" del modelo\n",
    "  imagen_prueba_2 = np.expand_dims(imagen_lista, axis=0)\n",
    "  #Realizamos predicción\n",
    "  prediction= model2.predict(imagen_prueba_2)\n",
    "  #reaizamos un filtro de los valores para crear la máscara\n",
    "  preds_train_t = (prediction > 0.7).astype(np.uint8)\n",
    "  #hacemos un stack\n",
    "  prediction_preparado = np.vstack(preds_train_t)\n",
    "  #calculamos el centroide\n",
    "  area = prediction_preparado.sum()\n",
    "  it = np.nditer(prediction_preparado, flags=['multi_index'])\n",
    "  for i in it:\n",
    "    x_c = i * it.multi_index[1] + x_c\n",
    "    y_c = i * it.multi_index[0] + y_c\n",
    "  (x_c,y_c) = int(x_c/area), int(y_c/area)\n",
    "\n",
    "#   b = (x_c - (img_1.shape[1])/2 )\n",
    "  #a = (y_c - img_1.shape[0])\n",
    "#   if b > 20:\n",
    "#         send(\"e\")\n",
    "#   elif b< -20:\n",
    "#     send(\"q\")\n",
    "#   else:\n",
    "#     send(\"a\")\n",
    "\n",
    "  #angulo = np.degrees(np.arctan(b/a))\n",
    "  #angulo_2 = str(angulo)\n",
    "  #send(angulo_2)\n",
    "  # creamos recurso para convertir a imagen a la máscara, de no ser así no se puede mostrar\n",
    "  matriz_para_hacer_imagen = np.zeros((256, 256,3))\n",
    "  imagen_mask = prediction_preparado + normalizedImg\n",
    "  #cv2.imshow('frame', imagen_mask)\n",
    "\n",
    "  # Cambio de prediction_preparado a rgb\n",
    "  prediction_preparado_rgb = cv2.cvtColor(prediction_preparado, cv2.COLOR_GRAY2RGB)*255\n",
    "  # Muestra de blending con prediction_preparado_rgb\n",
    "  im_blended = cv2.addWeighted(original, 1, prediction_preparado_rgb, 0.5, 0)\n",
    "  #creamos y añadimos a la imagen el centroide\n",
    "  image_with_circle = cv2.circle(im_blended, (x_c,y_c), radius=4, color=(0, 0, 255), thickness=-1)\n",
    "  cv2.imshow(\"outImg\", im_blended)\n",
    "  # Breaking out of the loop\n",
    "  if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "    break\n",
    "# Close down everything\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dbe341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambio de prediction_preparado a rgb\n",
    "prediction_preparado_rgb = cv2.cvtColor(prediction_preparado, cv2.COLOR_GRAY2RGB)\n",
    "print(prediction_preparado_rgb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e212175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.imshow(tf.keras.preprocessing.image.array_to_img(img2))\n",
    "plt.imshow(tf.keras.preprocessing.image.array_to_img(prediction_preparado), alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e693ebe",
   "metadata": {},
   "source": [
    "## Probando con cámara\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3174a1ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\davis\\AppData\\Local\\Temp\\ipykernel_12208\\744628863.py:44: RuntimeWarning: invalid value encountered in true_divide\n",
      "  (x_c,y_c) = (x_c/area), (y_c/area)\n",
      "C:\\Users\\davis\\AppData\\Local\\Temp\\ipykernel_12208\\744628863.py:44: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  (x_c,y_c) = (x_c/area), (y_c/area)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "\n",
    "cap= cv2.VideoCapture(0)\n",
    "\n",
    "width= int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height= int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "#puntos para el centroide\n",
    "x_c = 0\n",
    "y_c = 0\n",
    "#color para el punto del centroide\n",
    "red = [0,0,255]\n",
    "\n",
    "\n",
    "while True:\n",
    "  # Read frame \n",
    "  ret, frame = cap.read()\n",
    "  img_1 = cv2.resize(frame, (256, 256))\n",
    "  original = img_1 # Para blending\n",
    "  #recurso para normalización\n",
    "  normalizedImg = np.zeros((256, 256))\n",
    "  #normalizamos la imagen\n",
    "  img= cv2.normalize(img_1,  normalizedImg, 0, 255, cv2.NORM_MINMAX)\n",
    "  #convertimos a array\n",
    "  imagen_lista = tf.keras.preprocessing.image.array_to_img(img)\n",
    "  #expandimos dimensiones para que pueda ser digerida por \"Input\" del modelo\n",
    "  imagen_prueba_2 = np.expand_dims(imagen_lista, axis=0)\n",
    "  #Realizamos predicción\n",
    "  prediction= model2.predict(imagen_prueba_2)\n",
    "  #reaizamos un filtro de los valores para crear la máscara\n",
    "  preds_train_t = (prediction > 0.7).astype(np.uint8)\n",
    "  #hacemos un stack\n",
    "  prediction_preparado = np.vstack(preds_train_t)\n",
    "  #calculamos el centroide\n",
    "  area = prediction_preparado.sum()\n",
    "  it = np.nditer(prediction_preparado, flags=['multi_index'])\n",
    "  for i in it:\n",
    "    x_c = i * it.multi_index[1] + x_c\n",
    "    y_c = i * it.multi_index[0] + y_c\n",
    "  #convertimos a entero\n",
    "#   if x_c == np.nan or y_c == np.nan:\n",
    "#         continue\n",
    "\n",
    "  (x_c,y_c) = (x_c/area), (y_c/area)\n",
    "  if x_c == np.nan:\n",
    "    x_c = 0\n",
    "  else:\n",
    "    x_c = x_c.astype(int)\n",
    "  if y_c == np.nan:\n",
    "    y_c = 0\n",
    "  else:\n",
    "    y_c = y_c.astype(int)\n",
    "  #b es el valor del cateto opuesto y a es el valor del cateto adyacente\n",
    "  #b = ((img_1.shape[1])/2 - x_c)\n",
    "  #a = (y_c)\n",
    "  b = (x_c - (img_1.shape[1])/2 )\n",
    "#   if b > 20:\n",
    "#          send(\"e\")\n",
    "#   elif b< -20:\n",
    "#      send(\"q\")\n",
    "#   else:\n",
    "#      send(\"a\")\n",
    "\n",
    "  #angulo = np.degrees(np.arctan(b/a))\n",
    "  #angulo_2 = str(angulo)\n",
    "  #send('angulo_2')\n",
    "  # creamos recurso para convertir a imagen a la máscara, de no ser así no se puede mostrar\n",
    "\n",
    "  #imagen_mask = prediction_preparado + normalizedImg # \"normalizedImg\" es matriz para hacer imagen\n",
    "  #cv2.imshow('frame', imagen_mask)\n",
    "\n",
    "  # Cambio de prediction_preparado a rgb\n",
    "  prediction_preparado_rgb = cv2.cvtColor(prediction_preparado, cv2.COLOR_GRAY2RGB)*255\n",
    "  # Muestra de blending con prediction_preparado_rgb\n",
    "  im_blended = cv2.addWeighted(original, 1, prediction_preparado_rgb, 0.5, 0)\n",
    "  #creamos y añadimos a la imagen el centroide\n",
    "  image_with_circle = cv2.circle(im_blended, (x_c,y_c), radius=4, color=(0, 0, 255), thickness=-1)\n",
    "  cv2.imshow(\"outImg\", image_with_circle)\n",
    "  if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "    break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "#writer.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10c1517f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'original' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43moriginal\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'original' is not defined"
     ]
    }
   ],
   "source": [
    "original.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab955d8",
   "metadata": {},
   "source": [
    "## Probando cámara Álvaro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c97fba84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "0\n",
      "x--centroide: nan-xcenter: 128.0\n",
      "y--centroide: nan-ycenter: 255\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\davis\\AppData\\Local\\Temp\\ipykernel_524\\1033366780.py:46: RuntimeWarning: invalid value encountered in true_divide\n",
      "  (x_c,y_c) = (x_c/area), (y_c/area)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "integer argument expected, got float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    103\u001b[0m im_blended \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39maddWeighted(original, \u001b[38;5;241m1\u001b[39m, prediction_preparado_rgb, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m#creamos y añadimos a la imagen el centroide\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m image_with_circle \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcircle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim_blended\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_c\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradius\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthickness\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m image_with_circle_2 \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcircle(image_with_circle, (\u001b[38;5;241m128\u001b[39m,\u001b[38;5;241m256\u001b[39m), radius\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, color\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m), thickness\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    107\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutImg\u001b[39m\u001b[38;5;124m\"\u001b[39m, image_with_circle_2)\n",
      "\u001b[1;31mTypeError\u001b[0m: integer argument expected, got float"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "\n",
    "cap= cv2.VideoCapture(0)\n",
    "\n",
    "width= int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height= int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "#puntos para el centroide\n",
    "x_c = 0\n",
    "y_c = 0\n",
    "#color para el punto del centroide\n",
    "red = [0,0,255]\n",
    "\n",
    "\n",
    "while True:\n",
    "  # Read frame \n",
    "  ret, frame = cap.read()\n",
    "  img_1 = cv2.resize(frame, (256, 256))\n",
    "  original = img_1 # Para blending\n",
    "  #recurso para normalización\n",
    "  normalizedImg = np.zeros((256, 256))\n",
    "  #normalizamos la imagen\n",
    "  img= cv2.normalize(img_1,  normalizedImg, 0, 255, cv2.NORM_MINMAX)\n",
    "  #convertimos a array\n",
    "  imagen_lista = tf.keras.preprocessing.image.array_to_img(img)\n",
    "  #expandimos dimensiones para que pueda ser digerida por \"Input\" del modelo\n",
    "  imagen_prueba_2 = np.expand_dims(imagen_lista, axis=0)\n",
    "  #Realizamos predicción\n",
    "  prediction= model2.predict(imagen_prueba_2)\n",
    "  #reaizamos un filtro de los valores para crear la máscara\n",
    "  preds_train_t = (prediction > 0.7).astype(np.uint8)\n",
    "  #hacemos un stack\n",
    "  prediction_preparado = np.vstack(preds_train_t)\n",
    "  #calculamos el centroide\n",
    "  area = prediction_preparado.sum()\n",
    "  it = np.nditer(prediction_preparado, flags=['multi_index'])\n",
    "  for i in it:\n",
    "    x_c = i * it.multi_index[1] + x_c\n",
    "    y_c = i * it.multi_index[0] + y_c\n",
    "  #convertimos a entero\n",
    "  #print(type(x_c))\n",
    "  #print(y_c)\n",
    "  #print(x_c)\n",
    "  #print(x_c/area)\n",
    "  \n",
    "  (x_c,y_c) = (x_c/area), (y_c/area)\n",
    "\n",
    "#   if (abs(x_c)>500):\n",
    "#     x_c=0\n",
    "#     y_c=0\n",
    "        \n",
    "#   if x_c == np.nan:\n",
    "#     x_c = 0\n",
    "#   else:\n",
    "#     x_c = x_c.astype(int)\n",
    "#   if y_c == np.nan:\n",
    "#     y_c = 0\n",
    "#   else:\n",
    "#     y_c = y_c.astype(int)\n",
    "    \n",
    "#   if (abs(x_c)>500):\n",
    "#     x_c=0\n",
    "#     y_c=0\n",
    "    \n",
    "  y_center= 255\n",
    "  x_center= (img_1.shape[1])/2\n",
    "  angulo=0\n",
    "  EuclideanDistance=0\n",
    "  angulo = np.arctan((x_c-x_center)/abs(y_center-y_c))\n",
    "  print(angulo)\n",
    "  print(area)\n",
    "  print(\"x--\" +\"centroide: \" + str(x_c) + \"-\"+ \"xcenter: \"+ str(x_center))\n",
    "  print(\"y--\" +\"centroide: \"+ str(y_c) + \"-\"+ \"ycenter: \"+ str(y_center))\n",
    "  EuclideanDistance = np.sqrt((x_center-x_c)**2+(y_center-y_c)**2)\n",
    "  print(EuclideanDistance)\n",
    "     \n",
    "#><>><<\n",
    "  #send(str(angulo)+\",\"+ str(EuclideanDistance))\n",
    "\n",
    "#   #b es el valor del cateto opuesto y a es el valor del cateto adyacente\n",
    "#   #b = ((img_1.shape[1])/2 - x_c)\n",
    "#   #a = (y_c)\n",
    "#   b = (x_c - (img_1.shape[1])/2 )\n",
    "#   #a = (y_c - img_1.shape[0])\n",
    "#   if b > 20:\n",
    "#          send(\"e\")\n",
    "#   elif b< -20:\n",
    "#      send(\"q\")\n",
    "#   else:\n",
    "#      send(\"a\")\n",
    "\n",
    "  #angulo = np.degrees(np.arctan(b/a))\n",
    "  #angulo_2 = str(angulo)\n",
    "  #send('angulo_2')\n",
    "  # creamos recurso para convertir a imagen a la máscara, de no ser así no se puede mostrar\n",
    "\n",
    "  #imagen_mask = prediction_preparado + normalizedImg # \"normalizedImg\" es matriz para hacer imagen\n",
    "  #cv2.imshow('frame', imagen_mask)\n",
    "\n",
    "  # Cambio de prediction_preparado a rgb\n",
    "  prediction_preparado_rgb = cv2.cvtColor(prediction_preparado, cv2.COLOR_GRAY2RGB)*255\n",
    "  # Muestra de blending con prediction_preparado_rgb\n",
    "  im_blended = cv2.addWeighted(original, 1, prediction_preparado_rgb, 0.5, 0)\n",
    "  #creamos y añadimos a la imagen el centroide\n",
    "  image_with_circle = cv2.circle(im_blended, (x_c,y_c), radius=4, color=(0, 0, 255), thickness=-1)\n",
    "  image_with_circle_2 = cv2.circle(image_with_circle, (128,256), radius=4, color=(0, 0, 255), thickness=-1)\n",
    "  cv2.imshow(\"outImg\", image_with_circle_2)\n",
    "  if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "    break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "#writer.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "049743d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prediction_preparado' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mprediction_preparado\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prediction_preparado' is not defined"
     ]
    }
   ],
   "source": [
    "prediction_preparado.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4154a2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr = [-1]\n",
    "\n",
    "arctan_val = np.degrees(np.arctan(1))\n",
    "\n",
    "print(arctan_val)\n",
    "print(np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82237cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the opencv library\n",
    "import cv2\n",
    "  \n",
    "  \n",
    "# define a video capture object\n",
    "vid = cv2.VideoCapture(0)\n",
    "  \n",
    "while(True):\n",
    "      \n",
    "    # Capture the video frame\n",
    "    # by frame\n",
    "    ret, frame = vid.read()\n",
    "    img_1 = cv2.resize(frame, (256, 256))\n",
    "  \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', img_1)\n",
    "      \n",
    "    # the 'q' button is set as the\n",
    "    # quitting button you may use any\n",
    "    # desired button of your choice\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "  \n",
    "# After the loop release the cap object\n",
    "vid.release()\n",
    "# Destroy all the windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462de974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "def list_ports():\n",
    "    is_working = True\n",
    "    dev_port = 0\n",
    "    working_ports = []\n",
    "    available_ports = []\n",
    "    while is_working:\n",
    "        camera = cv2.VideoCapture(dev_port)\n",
    "        if not camera.isOpened():\n",
    "            is_working = False\n",
    "            print(\"Port %s is not working.\" %dev_port)\n",
    "        else:\n",
    "            is_reading, img = camera.read()\n",
    "            w = camera.get(3)\n",
    "            h = camera.get(4)\n",
    "            if is_reading:\n",
    "                print(\"Port %s is working and reads images (%s x %s)\" %(dev_port,h,w))\n",
    "                working_ports.append(dev_port)\n",
    "            else:\n",
    "                print(\"Port %s for camera ( %s x %s) is present but does not reads.\" %(dev_port,h,w))\n",
    "                available_ports.append(dev_port)\n",
    "        dev_port +=1\n",
    "    return available_ports,working_ports\n",
    "\n",
    "list_ports()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
